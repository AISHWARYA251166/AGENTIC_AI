{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AISHWARYA251166/AGENTIC_AI/blob/main/AI_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU2g93UlfMER"
      },
      "outputs": [],
      "source": [
        "# Read Colab secrets and export to env vars expected by the notebook\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "except Exception:\n",
        "    userdata = None\n",
        "\n",
        "def _get(*names):\n",
        "    for n in names:\n",
        "        try:\n",
        "            v = userdata.get(n) if userdata else None\n",
        "        except Exception:\n",
        "            v = None\n",
        "        if v:\n",
        "            return v.strip()\n",
        "    return None\n",
        "\n",
        "groq = _get(\"GROQ_API_KEY\", \"GROQ_API\")\n",
        "gemini = _get(\"GEMINI_API_KEY\", \"GEMINI_API\", \"GOOGLE_API_KEY\")\n",
        "\n",
        "if groq:  os.environ[\"GROQ_API_KEY\"] = groq\n",
        "if gemini: os.environ[\"GEMINI_API_KEY\"] = gemini\n",
        "\n",
        "print(\"GROQ set:\", bool(os.environ.get(\"GROQ_API_KEY\")))\n",
        "print(\"GEMINI set:\", bool(os.environ.get(\"GEMINI_API_KEY\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ_ZaKvsfQH5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.environ.get(\"GROQ_API_KEY\", \"\")[:6] + \"‚Ä¶\")\n",
        "print(os.environ.get(\"GEMINI_API_KEY\", \"\")[:6] + \"‚Ä¶\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JpVTcchQfWyg"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip -q install gradio groq google-generativeai pandas python-dateutil dateparser\n",
        "\n",
        "import os, re, json, tempfile\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import dateparser\n",
        "\n",
        "USE_GROQ = bool(os.environ.get(\"GROQ_API_KEY\"))\n",
        "USE_GEMINI = bool(os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "if not (USE_GROQ or USE_GEMINI):\n",
        "    print(\"üîë Set at least one key before running: \"\n",
        "          \"os.environ['GROQ_API_KEY']='...' or os.environ['GEMINI_API_KEY']='...'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hm-3Hx1kfxln"
      },
      "outputs": [],
      "source": [
        "# @title LLM helper\n",
        "def llm_call(system: str, user: str, temperature: float = 0.2) -> str:\n",
        "    if USE_GROQ:\n",
        "        from groq import Groq\n",
        "        client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            messages=[{\"role\": \"system\", \"content\": system},\n",
        "                      {\"role\": \"user\", \"content\": user}],\n",
        "            temperature=temperature,\n",
        "        )\n",
        "        print(\"resp:\", resp)\n",
        "        return resp.choices[0].message.content.strip()\n",
        "\n",
        "    if USE_GEMINI:\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        prompt = f\"System:\\n{system}\\n\\nUser:\\n{user}\"\n",
        "        resp = model.generate_content(prompt)\n",
        "        return resp.text.strip()\n",
        "\n",
        "    raise RuntimeError(\"No Api key found .set GROQ_API_KEY or GEMINI_API_KEY.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Tf9YrKdolxwj"
      },
      "outputs": [],
      "source": [
        "# @title Agent logic\n",
        "SYSTEM_PROMPT = \"\"\"You are a precise Meeting Notes Assistant.\n",
        "Given raw notes, return a compact JSON with:\n",
        "- summary: exactly 3 bullet points (short phrases).\n",
        "- decisions: list of decisions (0..5 concise items).\n",
        "- action_items: list of objects with keys:\n",
        "  task (imperative), owner (first name or role), due_date (natural language OK),\n",
        "  priority (High|Medium|Low). Only include real, actionable tasks.\n",
        "- email_subject: short subject line for a follow-up email.\n",
        "- email_body: 120-180 words, crisp recap + action items with owners & due dates.\n",
        "STRICTLY return only a JSON object. No code fences, no commentary.\n",
        "Keep writing professional, friendly, and unambiguous.\n",
        "\"\"\"\n",
        "\n",
        "USER_TEMPLATE = \"\"\"MEETING:\n",
        "Title: {title}\n",
        "DateTime (local): {meeting_dt}\n",
        "Notes:\n",
        "{notes}\n",
        "\n",
        "Constraints:\n",
        "- summary: exactly 3 bullets.\n",
        "- If a due date is hinted (e.g., ‚Äúnext Friday‚Äù), include it; else use \"TBD\".\n",
        "- Prioritize tasks that move metrics or remove blockers.\n",
        "Return only the JSON object.\n",
        "\"\"\"\n",
        "\n",
        "ALLOWED_PRIORITIES = {\"High\",\"Medium\",\"Low\"}\n",
        "\n",
        "import json, re\n",
        "\n",
        "def parse_json_loose(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract and safely parse JSON text returned from LLM output.\n",
        "    Handles newlines, stray characters, and fancy quotes automatically.\n",
        "    \"\"\"\n",
        "    # 1. Clean up leading and trailing whitespace/newlines\n",
        "    text = text.strip()\n",
        "\n",
        "    # 2. Extract the JSON block (anything between first { and last })\n",
        "    # This is critical if the LLM adds commentary/code fences\n",
        "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
        "    candidate = m.group(0).strip() if m else text.strip()\n",
        "\n",
        "    # 3. Clean unwanted characters (BOM, carriage returns, newlines *outside* of strings)\n",
        "    candidate = candidate.replace('\\r', '').replace('\\n', '')\n",
        "    candidate = candidate.replace('‚Äú', '\"').replace('‚Äù', '\"').replace(\"‚Äô\", \"'\")\n",
        "    candidate = candidate.lstrip(\"\\ufeff\").strip()  # remove BOM or spaces\n",
        "\n",
        "    # Try strict parse\n",
        "    try:\n",
        "        return json.loads(candidate)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"‚ö† JSON Decode failed once, retrying with relaxed fix:\", e)\n",
        "        # 4. Fallback for unescaped double quotes inside strings\n",
        "        # Note: This substitution is tricky and might not always be perfect.\n",
        "        # It attempts to escape quotes that are not followed by JSON structural characters.\n",
        "        # It's often better to instruct the LLM to return strict JSON.\n",
        "        candidate = re.sub(r'(?<!\\\\)\"(?![:,}\\]])', '\\\\\"', candidate)\n",
        "        return json.loads(candidate)\n",
        "\n",
        "\n",
        "def normalize_due_date(due_str: str, base_dt: datetime) -> str:\n",
        "    if not due_str or due_str.strip().upper() == \"TBD\":\n",
        "        return \"TBD\"\n",
        "    dt = dateparser.parse(\n",
        "        due_str,\n",
        "        settings={\"RELATIVE_BASE\": base_dt, \"PREFER_DATES_FROM\": \"future\"}\n",
        "    )\n",
        "    return dt.date().isoformat() if dt else due_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "afWLZq9Wl4P3",
        "outputId": "fbf8baac-d079-431b-b08c-dfa01357a57a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5744a87858deac793a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5744a87858deac793a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resp: ChatCompletion(id='chatcmpl-c7df2af0-62e0-4bdc-a30a-d9cbbc03a995', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"summary\": [\\n    \"Q3 target $1.2M, current commit $820k, upside $300k\",\\n    \"Prioritize deals needing low-effort security wins\",\\n    \"Address DeltaPower and Acme security concerns\"\\n  ],\\n  \"decisions\": [\\n    \"Prioritize deals needing low-effort security wins\"\\n  ],\\n  \"action_items\": [\\n    {\\n      \"task\": \"Schedule SecOps call with DeltaPower legal\",\\n      \"owner\": \"Arjun\",\\n      \"due_date\": \"Thursday\",\\n      \"priority\": \"High\"\\n    },\\n    {\\n      \"task\": \"Share SOC2 + DPA redlines with DeltaPower\",\\n      \"owner\": \"Sara\",\\n      \"due_date\": \"TBD\",\\n      \"priority\": \"High\"\\n    },\\n    {\\n      \"task\": \"Prepare 2 SSO case studies deck\",\\n      \"owner\": \"Mei\",\\n      \"due_date\": \"Next Monday\",\\n      \"priority\": \"Medium\"\\n    },\\n    {\\n      \"task\": \"Re-forecast and send to execs\",\\n      \"owner\": \"Luis\",\\n      \"due_date\": \"Friday 5pm\",\\n      \"priority\": \"High\"\\n    }\\n  ],\\n  \"email_subject\": \"Q3 Growth Marketing Sync Follow-up\",\\n  \"email_body\": \"We discussed Q3 growth targets and addressed key risks. To move forward, we\\'ve decided to prioritize deals with low-effort security wins. Action items include scheduling a SecOps call with DeltaPower legal by Thursday, sharing SOC2 + DPA redlines with DeltaPower, preparing SSO case studies, and re-forecasting. Please review the attached action items and let me know if you have any questions.\"\\n}', role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None))], created=1761391503, model='llama-3.1-8b-instant', object='chat.completion', system_fingerprint='fp_31e1ee87c5', usage=CompletionUsage(completion_tokens=358, prompt_tokens=413, total_tokens=771, completion_time=0.390060951, prompt_time=0.022709914, queue_time=0.072701578, total_time=0.412770865), usage_breakdown=None, x_groq={'id': 'req_01k8dhtsacejat5d2jbrt1xwx3'}, service_tier='on_demand')\n",
            "resp: ChatCompletion(id='chatcmpl-c6740ac8-e891-427b-9ad4-1eb32782e52b', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"summary\": [\\n    \"API endpoints nearing completion\",\\n    \"Social media creatives in design phase\",\\n    \"New mobile app launch on November 10\"\\n  ],\\n  \"decisions\": [\\n    \"Launch the new mobile app on November 10\",\\n    \"Run a teaser campaign one week before the official launch\"\\n  ],\\n  \"action_items\": [\\n    {\\n      \"task\": \"Finalize API endpoints and testing\",\\n      \"owner\": \"Rahul\",\\n      \"due_date\": \"Next week\",\\n      \"priority\": \"High\"\\n    },\\n    {\\n      \"task\": \"Prepare social media assets\",\\n      \"owner\": \"Priya\",\\n      \"due_date\": \"TBD\",\\n      \"priority\": \"Medium\"\\n    },\\n    {\\n      \"task\": \"Plan teaser campaign\",\\n      \"owner\": \"Marketing team\",\\n      \"due_date\": \"TBD\",\\n      \"priority\": \"High\"\\n    }\\n  ],\\n  \"email_subject\": \"Q3 Growth Marketing Sync Meeting Recap\",\\n  \"email_body\": \"The Q3 Growth Marketing Sync meeting covered the status of API endpoints, social media creative design, and the new mobile app launch. Key decisions include launching the app on November 10 and running a teaser campaign beforehand. Action items include finalizing API endpoints and testing by Rahul, preparing social media assets by Priya, and planning the teaser campaign by the marketing team. The next review meeting is scheduled for November 3. Please review and update your tasks accordingly.\"\\n}', role='assistant', executed_tools=None, function_call=None, reasoning=None, tool_calls=None))], created=1761391565, model='llama-3.1-8b-instant', object='chat.completion', system_fingerprint='fp_4dea31877a', usage=CompletionUsage(completion_tokens=307, prompt_tokens=404, total_tokens=711, completion_time=0.447404722, prompt_time=0.025165046, queue_time=0.075640488, total_time=0.472569768), usage_breakdown=None, x_groq={'id': 'req_01k8dhwnx2fjzbrdpg7kwewnxz'}, service_tier='on_demand')\n"
          ]
        }
      ],
      "source": [
        "# @title Gradio UI (runs in Colab)\n",
        "def run_agent(title, meeting_dt, notes):\n",
        "    # Fallbacks\n",
        "    title = (title or \"Team Sync\").strip()\n",
        "    meeting_dt = (meeting_dt or datetime.now().strftime(\"%Y-%m-%d %H:%M\")).strip()\n",
        "    notes = (notes or \"\").strip()\n",
        "\n",
        "    user = USER_TEMPLATE.format(title=title, meeting_dt=meeting_dt, notes=notes)\n",
        "    raw = llm_call(SYSTEM_PROMPT, user)\n",
        "\n",
        "    try:\n",
        "        js = parse_json_loose(raw)\n",
        "    except Exception as e:\n",
        "        return (\"\", f\"‚ö† Could not parse model output:\\n{raw}\\n\\nError: {e}\",\n",
        "                pd.DataFrame(), None)\n",
        "\n",
        "    # Normalize action items\n",
        "    try:\n",
        "        base_dt = datetime.fromisoformat(meeting_dt.replace(\"Z\",\"\").strip())\n",
        "    except:\n",
        "        base_dt = datetime.now()\n",
        "\n",
        "    for item in js.get(\"action_items\", []):\n",
        "        pr = str(item.get(\"priority\",\"\")).title()\n",
        "        item[\"priority\"] = pr if pr in ALLOWED_PRIORITIES else \"Medium\"\n",
        "        item[\"due_date\"] = normalize_due_date(item.get(\"due_date\",\"\"), base_dt)\n",
        "\n",
        "    # Build outputs\n",
        "    summary_md = \"### Summary (3 bullets)\\n\" + \"\\n\".join([f\"- {b}\" for b in js.get(\"summary\", [])])\n",
        "    decisions = js.get(\"decisions\", [])\n",
        "    decisions_md = \"### Decisions\\n\" + (\"\\n\".join([f\"- {d}\" for d in decisions]) if decisions else \"- (none)\")\n",
        "\n",
        "    # Dataframe + CSV\n",
        "    rows = []\n",
        "    for i, ai in enumerate(js.get(\"action_items\", []), 1):\n",
        "        rows.append({\n",
        "            \"idx\": i,\n",
        "            \"task\": ai.get(\"task\",\"\"),\n",
        "            \"owner\": ai.get(\"owner\",\"\"),\n",
        "            \"due_date\": ai.get(\"due_date\",\"\"),\n",
        "            \"priority\": ai.get(\"priority\",\"\"),\n",
        "        })\n",
        "    ai_df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"idx\",\"task\",\"owner\",\"due_date\",\"priority\"])\n",
        "\n",
        "    csv_path = None\n",
        "    if len(ai_df) > 0:\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
        "        ai_df.to_csv(tmp.name, index=False)\n",
        "        csv_path = tmp.name\n",
        "\n",
        "    email_block = f\"*Subject:* {js.get('email_subject','')}\\n\\n{js.get('email_body','')}\"\n",
        "    return summary_md + \"\\n\\n\" + decisions_md, email_block, ai_df, csv_path\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Meeting Minutes ‚Üí Action-Items Agent (Colab-friendly, Groq/Gemini)\")\n",
        "    with gr.Row():\n",
        "        title_in = gr.Textbox(label=\"Meeting Title\", value=\"Q3 Growth Marketing Sync\")\n",
        "        dt_in = gr.Textbox(label=\"Meeting Date/Time (local)\", value=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
        "    notes_in = gr.Textbox(label=\"Raw Notes\", lines=12, placeholder=\"Paste raw notes here...\")\n",
        "\n",
        "    run_btn = gr.Button(\"Extract Summary, Decisions, Action Items\")\n",
        "\n",
        "    out_summary = gr.Markdown()\n",
        "    out_email   = gr.Markdown()\n",
        "    out_table   = gr.Dataframe(headers=[\"idx\",\"task\",\"owner\",\"due_date\",\"priority\"], interactive=False)\n",
        "    out_file    = gr.File(label=\"Download Action Items CSV\")\n",
        "\n",
        "    run_btn.click(run_agent, inputs=[title_in, dt_in, notes_in],\n",
        "                  outputs=[out_summary, out_email, out_table, out_file])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTaKnBMRsuvG4tCoh51qeB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}